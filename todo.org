#+title: Todo

* TODO fucking important [1/11]
** TODO union [1/3]
in terms of representation, we just need =Vec<Value>= for now. later we can do specialization for common like =T | undefined=

*** DONE normalizing unions
*** TODO object edge case
this is a weird edge case:
#+begin_src typescript
type Extends<A, B> = A extends B ? "extends" : "not extends";

type a = { foo: 1 | 2 };
type b = { foo: 1 } | { foo: 2 };

// extends
type result = Extends<a, b>;
#+end_src

if we do the algorithm on objects where we check every key of =a= is subtype of every variant of union =b= it will fail, because:
#+begin_src typescript
// not extends
type result = Extends<1 | 2, 1>
// not extends
type result2 = Extends<1 | 2, 2>
#+end_src

there are a couple ways to solve this:
- specialized subtype impl for objects vs unions ::
  how would this look like?

  first we need to know when do apply this specialization. we need to be able to tell if =a= is an obect and =b= is a union of N objects where each object has a similar field but with different values.

  when we know the conditions for this specialization are met, then we dispatch to =extends_object_union= function.

  this will iterate the keys of =a=. if one key has a value that is a union, we check if the value subtypes the corresponding value in =b=.

- when "normalizing" unions we turn ={ foo: 1 } | { foo: 2 }= into ={ foo: 1 | 2 }=, or do this just before subtype checking
*** TODO disjoint edge case
if two unions are disjoint:
#+begin_src typescript
type ExtendsCheck<A, B> = A extends B ? "yes" : "no";
type t5 = ExtendsCheck<
  "NICE" | boolean | { lmao: boolean },
  string | boolean | number | { nice: string }
>;
#+end_src

the result is: "yes" | "no"

** DONE Unable to distinguish arrays and single-item tuples
I realized I made a very naive error in the way arrays/tuples are represented, which means that single-items and regular arrays are indistinguishable from each other which is bad.
** TODO non-object type keys
all types are actually objects and have additional keys

for example =number= has =toExponential=, =toFixed=, etc.

so each type has like its base number of keys, so we dont have to make every type an =Object=, instead when we type check =string=, =bool=, =number=, etc. against object we just check against these known base keys

the problem is when you add more types to this base amount:
#+begin_src typescript
type agumentednumber = number & { foo(): void }
#+end_src

We have several options:
1. put a =base= field on the =Object= struct which tells us where to get the base keys ::
   problem is that =number=, =string= aren't actually objects see the Test<A, B> thing below. you can't make an
   object with all the fields of a number and have it be a number

   so we want to still have our distinction
2. or just merge the base keys onto the =fields= of an =Object= ::
   same problem as above
3. create an "augmented" type which contains the type and additional fields ::
   Something like this:
    #+begin_src rust
    struct AugmentedType {
        base: Value,
        augmentation: Object
    }
    #+end_src

4. have special heap allocated variants of keyword types =Number=, =String=, =Boolean=

#+begin_src typescript
type Test<A, B> = A extends B ? "extends" : "not extends";
type fakenumber = {
  toExponential(fractionDigits?: number | undefined): string;
  toFixed(fractionDigits?: number | undefined): string;
  toLocaleString(
    locales?: string | string[] | undefined,
    options?: Intl.NumberFormatOptions | undefined
  ): string;
  toPrecision(precision?: number | undefined): string;
  toString(radix?: number | undefined): string
  valueOf(): number
};

// this returns "not extends"
type result = Test<fakenumber, number>
#+end_src
** TODO optional fields/types
we have optional types:
#+begin_src typescript
type OptionalInObject = {
  foo?: boolean
}
type OptionalInTuple = [foo?: string]
#+end_src

how do we handle this?

first intuition is to treat them as union like: =T | undefined=.
indeed, when you hover over =OptionalInObject= or =OptionalInTuple=, the optional fields become: =foo?: boolean | undefined=
but we need to make sure that the semantics between =foo?: boolean= and this union represenation map over sufficiently enough to do this.
basically what i want to know is if we can erase the concept of "optionals" completely from the IR and treat them literally as =T | undefined=

the issue is that an optional field actually allows you to omit the field in instantiating the type:
#+begin_src typescript
// is okay
const test: OptionalInObject = {}

type NOOptionalInObject = {
  foo: boolean | undefined
}
// not okay, complains we are missing `foo`
const notOkay: OptionalInObject = {}
#+end_src

and I made sure to check this was the same in type-level typescript:
#+begin_src typescript
type OptionalInObject = {
  optional?: boolean;
};
type NOOptionalInObject = {
  optional: boolean | undefined;
};

type Check<T> = T extends NOOptionalInObject ? "YAY" : "NOO";
// result is NOO
type CheckResult = Check<{}>;
#+end_src

so we need to preserve this optional information
** TODO index num lit
can speed up index operations if we make specialization ops for indexing

for example =myarray[0]= is a common expression, specifically indexing with a number constant literal
** TODO =length= key on arrays
** TODO string interning
this is really important, otherwise string value equality won't work
** TODO make =extends= a method on =Value= so it can be used in compiler??
** TODO string interpolation
** TODO unions
** TODO GC
* TODO brainstorming
** TODO use immutable / persistent data structures
all values in type-level typescript are immutable. langs with focus on immutability tend to be allocation heavy (you need to make more objects)

fp langs solve this by using persistent data structures which typically have some structural sharing mechanism to reduce allocations for copies

https://github.com/immutable-js/immutable-js/ readme links:
- hash map tries ([[https://en.wikipedia.org/wiki/Hash_array_mapped_trie][link]])
- vector tries ([[https://hypirion.com/musings/understanding-persistent-vector-pt-1][link]])

there are some rust crates that implement persistent data structures, but they are designed for safe rust.  they all have some reference counting shit going on. i don't know

** TODO idea for using stack for objects
what if the key/vals for an object were a slice/window of the stack?
** TODO Make ir repr more compact
some places where we can box stuff
* TODO archive
** DONE globals non-forward declarations all fucked lol
evaluation of order can't be strictly top down

this a little more complicated

need to build DAG of global declarations and the declarations they depend on

What to do with this?
#+begin_src typescript
type Fib<X extends number> = FibIter<X, 2, 1, 0>
type FibIter<X, I, Prev, PrevPrev> = /* ... */
type Main = WriteFile<
  "./fib-result.ts",
  ToTypescriptSource<"FibonacciResult", Fib<amount>>
>;

type amount = Main;
#+end_src

all globals will be the roots of the stmt nodes
process them first, add to =globals=
then when actually compiling the global, need to check if we already compiled so we dont have people redefining vars

** DONE main argv
** DONE let decls
this is my strategy:

executing a let decl will add another local to the function.
since we have the requirement that all exprs when finished executing will leave the stack as it was before, we can be certain that
pushing this local to the stack will be after the locals of the params + any other locals form let decls:
#+begin_src bash
STACK:
param1 param2 param3 letdecl1 letdecl2 letdecl3
#+end_src

when you enter the true branch of a let decl, we should push that local
#+begin_src typescript
type TestLet<Arg> = Arg extends infer val extends 0 ? val : "nope";
#+end_src
(the new bound var doesn't exist in the else branch)

the only problem is then getting rid of these new let decl vars.

** DONE arrays
to store we just need a vec of types

there are three kinds of arrays:
1. =Array<T>= or =T[]=
2. =[T, K, etc]=
3. =[and: T, labeled: K, etc]=

2 & 3 are actually tuples, but we should treat them the same bc they tuple extends array

also note that the labels in tuples dont matter for typechecking, they are just to make shit readable. so we can store them elsewhere and not give a fuck.

we could make a inline special representation. =Vec= is 24 bytes. =Value= is 8
usually the array type is just a =Value=
if its a tuple with 2-3 elements we can inline it probably
else just pass the =Vec=

we shouldnt even use vec (because of borrowck)
instead we can use our own repr with ptr + len

also
* preparation 2 show friends
union exmaple
* constant pool

In rust we have this:
#+begin_src rust
#[derive(Copy, Clone)]
pub struct Value(u64);
#+end_src

It can be a keyword type, f64, or object ptr.

The first two can be inlined directly, but object ptr is tricky.

For objects ptr they can point to:
#+begin_src rust
/// StringRef can either be InlinedString or HeapString
#[derive(Copy, Clone)]
#[repr(transparent)]
pub struct StringRef(u128);

#[derive(Copy, Clone)]
pub struct InlinedString {
    pub tag_and_len: u8,
    pub chars: [u8; 15],
}

#[derive(Clone, Copy)]
pub struct HeapString {
    pub ptr: *mut u8,
    pub len: usize,
}

#[derive(Clone)]
pub struct Object {
    /// INVARIANT: must be lexographically ordered so binary search works
    pub fields: Vec<ObjectField>,
}

#[derive(Clone, Copy, Debug)]
pub struct ObjectField(pub *mut StringRef, pub Value);

#[derive(Clone, Debug)]
pub enum Array {
    Tuple(Vec<Value>),
    Single(Value),
}
#+end_src

 In the bytecode it doesnt make sense to store the pointer. We could probably just store the object data right there.

So what does the object data look like? Do we want it to actually work like a runtime =Value=, or do they need different representations? If the latter, then we probably need to create all the constants on the heap when the VM loads the bytecode. If the former, you have to patch the pointers when the VM loads the bytecode.

I think patching the pointers is the right way to go. At first, all "pointers" will just be offsets. Then when we load bytecode we patch them, should just be a simple increment by base pointer.
* Refactor everything
Think I'm just gonna refactor everything.

- Compiler ::
  Everything needs to be serializable.

  What is currently NOT serializable:
  - Heap allocated objects (array/object/string) ::
    First "object" is a bad name. Just call them HeapValue or something?
  - Functions ::
    Currently stored in a =BTreeMap<String, Function<'alloc>>=.

    Inside functions, there is a =Chunk= which has a non-serializable =Vec<u8>= and =Vec<Value>= of constants.
  - Globals ::
    Currently a =HashMap<String, usize>=. Key being name, usize being index into constant pool of current function

  We need to design how these are laid out in memory.

  First, there should be a "constant pool". Just a chunk of memory where are all the constants live.
  - Some details about the constant pool ::

    There are heap allocated objects that may be constants. For example a string. The solution is to have a =Constant= type:

    #+begin_src rust
    enum Constant {
        Number(f64),
        Boolean(bool),
        // directly after are `len` bytes for string
        String { len: usize },
        // directly after are `len` other indices to constants
        Array { len: usize }
    }
    #+end_src
  - ChatGPT ::
    Given the problem you've described, using a constant pool is a sensible approach. The concept of a constant pool is well-established in the design of virtual machines, like the JVM, because it allows the VM to manage variable-size data efficiently.

    Here's a general approach to creating a constant pool and making your bytecode serializable:

    1. **Constant Pool Design**:
       - Each entry in the constant pool has a unique index.
       - Entries can be of variable length.
       - Precede each entry with a length indicator so that you can determine where the next entry begins.
       - When serializing the constant pool, prefix the entire pool with a total count of entries or a total length, so that the VM knows how much memory to allocate or how many entries to expect.

    2. **Bytecode Serialization**:
       - Instructions that use constant pool values don't embed the value directly. Instead, they embed the index of the value in the constant pool.
       - When serializing bytecode, replace pointers to heap-allocated values (like strings or arrays) with the corresponding index in the constant pool.
       - On deserialization, the VM will use these indices to reference the actual values in the constant pool.

    3. **Constant Pool Serialization**:
       - Serialize each entry based on its type:
         * Numbers (f64): Directly serialize the 64 bits.
         * Booleans: Can be represented by a single byte.
         * Strings: Serialize the length followed by the actual characters.
         * Arrays: Serialize the length followed by the serialized form of each value.
       - The deserialization process involves reading back each entry, allocating the necessary memory, and restoring the value.

    4. **Memory Management**:
       - Once the bytecode is loaded into the VM, the VM can create a local representation of the constant pool in memory. This involves allocating memory for strings and arrays and setting up the necessary references.
       - This will also require a garbage collection strategy or reference counting to manage the lifecycle of these objects, especially if your VM supports dynamic operations on them.

    5. **Consider Alignment and Endianness**:
       - Depending on the target architectures of your VM, you might need to consider the alignment of your serialized data.
       - Also, take into account the endianness of your data, especially when transferring between machines with different endianness. You might want to adopt a standard endianness for serialization and then convert as needed during deserialization.

    6. **Versioning**:
       - It's a good idea to include a version number in the serialized bytecode. This way, if you make changes to the VM or bytecode format in the future, you can still support older bytecode formats.

    With the above approach, the bytecode becomes independent of any specific memory address, making it portable across different machines and VM instances. The process of serialization and deserialization effectively abstracts away the specifics of memory management, allowing you to focus on VM execution.
